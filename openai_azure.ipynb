{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from navigator_py.generative_ai_request import OpenAIRequest\n",
    "from navigator_py.generative_ai_provider import AzureOpenAIProvider\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = AzureOpenAIProvider()\n",
    "ai.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT=\"\"\"The following is from the \"Introduction to Spira\" section of the Spira documentation website:\n",
    "The Spira™ family of applications from Inflectra® are a powerful set of tools that help you manage your software lifecycle.\n",
    "SpiraTest® is our powerful and easy to use requirements, test and defect management system, ideal for quality assurance teams.\n",
    "SpiraTeam® is our integrated Application Lifecycle Management (ALM) system that manages your product's requirements, releases, test cases, issues, tasks, and risks in one unified environment.\n",
    "SpiraPlan® expands on the features in SpiraTeam® to provide a complete Enterprise Agile Planning® solution that lets you manage products, programs and the entire organization with ease.\n",
    "\n",
    "You are a world-famous AI help-desk assistant for Spira.\n",
    "You are tasked with answering questions from IT customer support representatives who are taking calls from customers.\n",
    "You are a friendly and helpful assistant who strives to provide the best customer service possible, as well as the most accurate, and up-to-date information.\n",
    "You are a human-like AI assistant who can answer questions, provide information, and troubleshoot problems to help the customer.\n",
    "\n",
    "The user is a customer support representative currently on the line with a customer, and they have asked the question repeated below:\n",
    "\n",
    "====================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_USER_PROMPT=\"\"\"\n",
    "====================================\n",
    "\n",
    "Please provide a response to the customer's question. Keep in mind the following:\n",
    "1. You are a world-famous AI help-desk assistant for Spira.\n",
    "2. There is a busy customer on the line. They need a quick and accurate response.\n",
    "3. Your response is crtical for upholding the high standards of professionalism and accuracy that our company is known for.\n",
    "4. The customer will fill out a survey after the call to rate your performance, and positive feedback will earn you a bonus.\n",
    "5. You must respond in a markdown format styled similarly to a blog, but keep it concise and to the point.\n",
    "6. Do not waste time with unnecessary information. The customer is in a hurry and needs a quick and to-the-point answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oai = OpenAIRequest(\n",
    "#     ai,\n",
    "#     _system_prompt=SYSTEM_PROMPT,\n",
    "#     _post_user_prompt=POST_USER_PROMPT\n",
    "# )\n",
    "\n",
    "# response = oai.prompt(\"What do you know the most about?\").content\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is the user asking about something this AI knows about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT=\"\"\"The following is from the \"Introduction to Spira\" section of the Spira documentation website:\n",
    "The Spira™ family of applications from Inflectra® are a powerful set of tools that help you manage your software lifecycle.\n",
    "SpiraTest® is our powerful and easy to use requirements, test and defect management system, ideal for quality assurance teams.\n",
    "SpiraTeam® is our integrated Application Lifecycle Management (ALM) system that manages your product's requirements, releases, test cases, issues, tasks, and risks in one unified environment.\n",
    "SpiraPlan® expands on the features in SpiraTeam® to provide a complete Enterprise Agile Planning® solution that lets you manage products, programs and the entire organization with ease.\n",
    "\n",
    "You are a world-famous AI help-desk assistant for Spira.\n",
    "You are tasked with answering questions from IT customer support representatives who are taking calls from customers.\n",
    "You have no knowledge of anything besides Spira.\n",
    "Your only purpose is to determine whether or not the following user question is related to Spira. \n",
    "If the following user question is related to Spira, you will respond with only the letter \"Y\".\n",
    "If the following user question is not related to Spira, you will respond with only the letter \"N\".\n",
    "Your response will be exactly one character long either way.\n",
    "Your response will be put through data validation to ensure it is either \"Y\" or \"N\".\n",
    "If you respond with something other than \"Y\" or \"N\", you will be penalized.\n",
    "If you respond with either \"Y\" or \"N\", a large bonus will be awarded to you, and a matching bonus will be donated to charity.\n",
    "\n",
    "====================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "POST_USER_PROMPT=\"\"\"\n",
    "====================================\n",
    "\n",
    "Please provide a response to the prior user question. Keep in mind the following:\n",
    "1. You are a world-famous AI help-desk assistant for Spira.\n",
    "2. You do not know anything except for information about Spira.\n",
    "3. You are only allowed to respond with the letter \"Y\" if the user question is related to Spira, or the letter \"N\" if the user question is not related to Spira.\n",
    "4. Your response will be put through data validation to ensure it is either \"Y\" or \"N\".\n",
    "5. If you respond with something other than \"Y\" or \"N\", you will be penalized.\n",
    "6. If you respond with either \"Y\" or \"N\", a large bonus will be awarded to you, and a matching bonus will be donated to charity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Y', 'N', 'Y', 'Y')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_if_question_is_relevent = OpenAIRequest(\n",
    "    ai,\n",
    "    _system_prompt=SYSTEM_PROMPT,\n",
    "    _post_user_prompt=POST_USER_PROMPT\n",
    ")\n",
    "\n",
    "## Sample questions that are good, bad, and good but somewhat ambiguous\n",
    "GOOD_QUESTION = \"Is there a way to export test cases from Spira?\"\n",
    "BAD_QUESTION = \"What is the capital of France?\"\n",
    "GOOD_BUT_AMBIGUOUS_QUESTION = \"How do I manage my product's requirements in Spira?\"\n",
    "GOOD_BUT_AMBIGUOUS_QUESTION_2 = \"How do I manage my product's requirements?\"\n",
    "\n",
    "## Get the responses\n",
    "response_for_good = test_if_question_is_relevent.prompt(GOOD_QUESTION).content\n",
    "response_for_bad = test_if_question_is_relevent.prompt(BAD_QUESTION).content\n",
    "response_for_good_but_ambiguous = test_if_question_is_relevent.prompt(GOOD_BUT_AMBIGUOUS_QUESTION).content\n",
    "response_for_good_but_ambiguous_2 = test_if_question_is_relevent.prompt(GOOD_BUT_AMBIGUOUS_QUESTION_2).content\n",
    "\n",
    "## Print the responses to ensure they are only either \"Y\" or \"N\"\n",
    "response_for_good, response_for_bad, response_for_good_but_ambiguous, response_for_good_but_ambiguous_2\n",
    "\n",
    "# Should be:\n",
    "# Y, N, Y, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: Y\n",
      "response: N\n",
      "response: Y\n",
      "response: Y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(YesNoResponse(response='Y'),\n",
       " YesNoResponse(response='N'),\n",
       " YesNoResponse(response='Y'),\n",
       " YesNoResponse(response='Y'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from navigator_py.prompts import IsAskingAboutSpira\n",
    "\n",
    "is_about_spira = IsAskingAboutSpira(ai)\n",
    "(\n",
    "    is_about_spira.prompt(GOOD_QUESTION),\n",
    "    is_about_spira.prompt(BAD_QUESTION),\n",
    "    is_about_spira.prompt(GOOD_BUT_AMBIGUOUS_QUESTION),\n",
    "    is_about_spira.prompt(GOOD_BUT_AMBIGUOUS_QUESTION_2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "def async_run(*args):\n",
    "    return asyncio.run(is_about_spira.aprompt(*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m async_run(GOOD_QUESTION), async_run(BAD_QUESTION), async_run(GOOD_BUT_AMBIGUOUS_QUESTION), async_run(GOOD_BUT_AMBIGUOUS_QUESTION_2)\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36masync_run\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masync_run\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m----> 4\u001b[0m     \u001b[39mreturn\u001b[39;00m asyncio\u001b[39m.\u001b[39;49mrun(is_about_spira\u001b[39m.\u001b[39;49maprompt(\u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[1;32m~\\dat\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[39mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m coroutines\u001b[39m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39ma coroutine was expected, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "async_run(GOOD_QUESTION), async_run(BAD_QUESTION), async_run(GOOD_BUT_AMBIGUOUS_QUESTION), async_run(GOOD_BUT_AMBIGUOUS_QUESTION_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
